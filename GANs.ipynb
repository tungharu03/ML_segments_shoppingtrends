{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0040115b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from IPython.display import Image\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4d09e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3900 entries, 0 to 3899\n",
      "Data columns (total 19 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Customer ID               3900 non-null   int64  \n",
      " 1   Age                       3900 non-null   int64  \n",
      " 2   Gender                    3900 non-null   object \n",
      " 3   Item Purchased            3900 non-null   object \n",
      " 4   Category                  3900 non-null   object \n",
      " 5   Purchase Amount (USD)     3900 non-null   int64  \n",
      " 6   Location                  3900 non-null   object \n",
      " 7   Size                      3900 non-null   object \n",
      " 8   Color                     3900 non-null   object \n",
      " 9   Season                    3900 non-null   object \n",
      " 10  Review Rating             3900 non-null   float64\n",
      " 11  Subscription Status       3900 non-null   object \n",
      " 12  Payment Method            3900 non-null   object \n",
      " 13  Shipping Type             3900 non-null   object \n",
      " 14  Discount Applied          3900 non-null   object \n",
      " 15  Promo Code Used           3900 non-null   object \n",
      " 16  Previous Purchases        3900 non-null   int64  \n",
      " 17  Preferred Payment Method  3900 non-null   object \n",
      " 18  Frequency of Purchases    3900 non-null   object \n",
      "dtypes: float64(1), int64(4), object(14)\n",
      "memory usage: 579.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data\\shopping_trends.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4407993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo từ điển ánh xạ cho \"Gender\"\n",
    "gender_mapping = {'Male': 1, 'Female': 2}\n",
    "df['Gender'] = df['Gender'].map(gender_mapping).astype(int)\n",
    "\n",
    "\n",
    "# Tạo một từ điển ánh xạ cho \"Item Purchased\"\n",
    "item_mapping = {\n",
    "    'Blouse': 1, 'Jewelry': 2, 'Pants': 3, 'Shirt': 4, 'Dress': 5,\n",
    "    'Sweater': 6, 'Jacket': 7, 'Belt': 8, 'Sunglasses': 9, 'Coat': 10,\n",
    "    'Sandals': 11, 'Socks': 12, 'Skirt': 13, 'Shorts': 14, 'Scarf': 15,\n",
    "    'Hat': 16, 'Handbag': 17, 'Hoodie': 18, 'Shoes': 19, 'T-shirt': 20,\n",
    "    'Sneakers': 21, 'Boots': 22, 'Backpack': 23, 'Gloves': 24, 'Jeans': 25\n",
    "}\n",
    "# Ánh xạ giá trị trong cột \"Item Purchased\" sang số\n",
    "df[\"Item Purchased\"] = df[\"Item Purchased\"].map(item_mapping).astype(int)\n",
    "\n",
    "\n",
    "# Tạo từ điển ánh xạ cho \"Category\"\n",
    "category_mapping = {'Clothing': 1, 'Accessories': 2, 'Footwear': 3, 'Outerwear': 4}\n",
    "df[\"Category\"] = df[\"Category\"].map(category_mapping).astype(int)\n",
    "\n",
    "\n",
    "# Tạo từ điển ánh xạ cho \"Location\"\n",
    "location_mapping = {\n",
    "    'Montana': 1, 'California': 2, 'Idaho': 3, 'Illinois': 4, 'Alabama': 5, \n",
    "    'Minnesota': 6, 'Nebraska': 7, 'New York': 8, 'Nevada': 9, 'Maryland': 10, \n",
    "    'Delaware': 11, 'Vermont': 12, 'Louisiana': 13, 'North Dakota': 14, 'Missouri': 15, \n",
    "    'West Virginia': 16, 'New Mexico': 17, 'Mississippi': 18, 'Indiana': 19, 'Georgia': 20, \n",
    "    'Kentucky': 21, 'Arkansas': 22, 'North Carolina': 23, 'Connecticut': 24, 'Virginia': 25, \n",
    "    'Ohio': 26, 'Tennessee': 27, 'Texas': 28, 'Maine': 29, 'South Carolina': 30, \n",
    "    'Colorado': 31, 'Oklahoma': 32, 'Wisconsin': 33, 'Oregon': 34, 'Pennsylvania': 35, \n",
    "    'Washington': 36, 'Michigan': 37, 'Alaska': 38, 'Massachusetts': 39, 'Wyoming': 40, \n",
    "    'Utah': 41, 'New Hampshire': 42, 'South Dakota': 43, 'Iowa': 44, 'Florida': 45, \n",
    "    'New Jersey': 46, 'Hawaii': 47, 'Arizona': 48, 'Kansas': 49, 'Rhode Island': 50\n",
    "}\n",
    "df['Location'] = df['Location'].map(location_mapping).astype(int)\n",
    "\n",
    "\n",
    "# Tạo một từ điển ánh xạ cho \"Size\"\n",
    "size_mapping = {'S': 1, 'M': 2, 'L': 3, 'XL': 4}\n",
    "df[\"Size\"] = df[\"Size\"].map(size_mapping).astype(int)\n",
    "\n",
    "\n",
    "# Tạo một từ điển ánh xạ cho \"Color\"\n",
    "color_mapping = {\n",
    "    'Olive': 1, 'Yellow': 2, 'Silver': 3, 'Teal': 4, 'Green': 5,\n",
    "    'Black': 6, 'Cyan': 7, 'Violet': 8, 'Gray': 9, 'Maroon': 10,\n",
    "    'Orange': 11, 'Charcoal': 12, 'Pink': 13, 'Magenta': 14, 'Blue': 15,\n",
    "    'Purple': 16, 'Peach': 17, 'Red': 18, 'Beige': 19, 'Indigo': 20,\n",
    "    'Lavender': 21, 'Turquoise': 22, 'White': 23, 'Brown': 24, 'Gold': 25\n",
    "}\n",
    "df[\"Color\"] = df[\"Color\"].map(color_mapping).astype(int)\n",
    "\n",
    "\n",
    "# Tạo một từ điển ánh xạ cho \"Season\"\n",
    "season_mapping = {'Spring': 1, 'Fall': 2, 'Winter': 3, 'Summer': 4}\n",
    "df[\"Season\"] = df[\"Season\"].map(season_mapping).astype(int)\n",
    "\n",
    "\n",
    "# Tạo từ điển ánh xạ cho \"Subscription Status\"\n",
    "subscription_mapping = {'No': 1, 'Yes': 2}\n",
    "df[\"Subscription Status\"] = df[\"Subscription Status\"].map(subscription_mapping).astype(int)\n",
    "\n",
    "\n",
    "# Tạo từ điển ánh xạ cho \"Payment Method\"\n",
    "payment_method_mapping = {'PayPal': 1, 'Credit Card': 2, 'Cash': 3, 'Debit Card': 4, \n",
    "                          'Venmo': 5, 'Bank Transfer': 6}\n",
    "df[\"Payment Method\"] = df[\"Payment Method\"].map(payment_method_mapping).astype(int)\n",
    "\n",
    "\n",
    "# Tạo từ điển ánh xạ cho \"Shipping Type\"\n",
    "shipping_mapping = {'Free Shipping': 1, 'Standard': 2, 'Store Pickup': 3, 'Next Day Air': 4, \n",
    "                    'Express': 5, '2-Day Shipping': 6}\n",
    "df[\"Shipping Type\"] = df[\"Shipping Type\"].map(shipping_mapping).astype(int)\n",
    "\n",
    "\n",
    "# Tạo từ điển ánh xạ cho \"Discount Applied\"\n",
    "binary_mapping = {'Yes': 1, 'No': 2}\n",
    "df[\"Discount Applied\"] = df[\"Discount Applied\"].map(binary_mapping).astype(int)\n",
    "\n",
    "\n",
    "# Tạo từ điển ánh xạ cho \"Preferred Payment Method\"\n",
    "prefered_payment_method_mapping = {'PayPal': 1, 'Credit Card': 2, 'Cash': 3, 'Debit Card': 4, \n",
    "                          'Venmo': 5, 'Bank Transfer': 6}\n",
    "df[\"Preferred Payment Method\"] = df[\"Preferred Payment Method\"].map(prefered_payment_method_mapping)\n",
    "\n",
    "\n",
    "# Tạo từ điển ánh xạ cho \"Frequency of Purchases\"\n",
    "frequency_mapping = {'Every 3 Months': 1, 'Annually': 2, 'Quarterly': 3, 'Monthly': 4, \n",
    "                     'Bi-Weekly': 5, 'Fortnightly': 6, 'Weekly': 7}\n",
    "df['Frequency of Purchases'] = df['Frequency of Purchases'].map(frequency_mapping).astype(int)\n",
    "\n",
    "\n",
    "\n",
    "# Tạo từ điển ánh xạ cho \"Review Rating\"\n",
    "def map_review_rating(rating):\n",
    "    if rating <= 1.9:\n",
    "        return 1\n",
    "    elif rating <= 2.9:\n",
    "        return 2\n",
    "    elif rating <= 3.9:\n",
    "        return 3\n",
    "    elif rating <= 4.9:\n",
    "        return 4\n",
    "    else:\n",
    "        return 5\n",
    "\n",
    "df[\"Review Rating\"] = df[\"Review Rating\"].map(map_review_rating).astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b866605a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3900 entries, 0 to 3899\n",
      "Data columns (total 15 columns):\n",
      " #   Column                    Non-Null Count  Dtype\n",
      "---  ------                    --------------  -----\n",
      " 0   Gender                    3900 non-null   int32\n",
      " 1   Age                       3900 non-null   int64\n",
      " 2   Category                  3900 non-null   int32\n",
      " 3   Item Purchased            3900 non-null   int32\n",
      " 4   Size                      3900 non-null   int32\n",
      " 5   Color                     3900 non-null   int32\n",
      " 6   Season                    3900 non-null   int32\n",
      " 7   Location                  3900 non-null   int32\n",
      " 8   Subscription Status       3900 non-null   int32\n",
      " 9   Payment Method            3900 non-null   int32\n",
      " 10  Shipping Type             3900 non-null   int32\n",
      " 11  Preferred Payment Method  3900 non-null   int64\n",
      " 12  Previous Purchases        3900 non-null   int64\n",
      " 13  Review Rating             3900 non-null   int32\n",
      " 14  Frequency of Purchases    3900 non-null   int32\n",
      "dtypes: int32(12), int64(3)\n",
      "memory usage: 274.3 KB\n"
     ]
    }
   ],
   "source": [
    "data_rf = df[['Gender','Age', 'Category','Item Purchased','Size','Color','Season','Location','Subscription Status', 'Payment Method','Shipping Type','Preferred Payment Method','Previous Purchases','Review Rating','Frequency of Purchases']]\n",
    "data_rf.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d15d782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, [D loss: 0.6722213625907898], [G loss: 0.7037363052368164]\n",
      "Epoch 100, [D loss: 0.6050056219100952], [G loss: 0.8436411619186401]\n",
      "Epoch 200, [D loss: 0.5188010334968567], [G loss: 1.4865316152572632]\n",
      "Epoch 300, [D loss: 0.6563220024108887], [G loss: 0.6344395875930786]\n",
      "Epoch 400, [D loss: 1.0326451063156128], [G loss: 0.7504651546478271]\n",
      "Epoch 500, [D loss: 0.7737165689468384], [G loss: 0.7050666809082031]\n",
      "Epoch 600, [D loss: 0.7121861577033997], [G loss: 0.8895190954208374]\n",
      "Epoch 700, [D loss: 0.7021465301513672], [G loss: 0.8188849091529846]\n",
      "Epoch 800, [D loss: 0.7369410991668701], [G loss: 0.6830068230628967]\n",
      "Epoch 900, [D loss: 0.7639302015304565], [G loss: 0.5799871683120728]\n",
      "Epoch 1000, [D loss: 0.710030198097229], [G loss: 0.6119928956031799]\n",
      "Epoch 1100, [D loss: 0.6740131378173828], [G loss: 0.6178276538848877]\n",
      "Epoch 1200, [D loss: 0.6930288076400757], [G loss: 0.6232801079750061]\n",
      "Epoch 1300, [D loss: 0.7551901936531067], [G loss: 0.8213179707527161]\n",
      "Epoch 1400, [D loss: 0.6889495849609375], [G loss: 0.7849599123001099]\n",
      "Epoch 1500, [D loss: 0.7732012271881104], [G loss: 0.825086236000061]\n",
      "Epoch 1600, [D loss: 0.8931575417518616], [G loss: 0.6565285325050354]\n",
      "Epoch 1700, [D loss: 0.6897265911102295], [G loss: 0.8489127159118652]\n",
      "Epoch 1800, [D loss: 0.5820645689964294], [G loss: 0.6879806518554688]\n",
      "Epoch 1900, [D loss: 0.7865380048751831], [G loss: 0.6478195786476135]\n",
      "Epoch 2000, [D loss: 0.6642577648162842], [G loss: 0.739827573299408]\n",
      "Epoch 2100, [D loss: 0.7152807712554932], [G loss: 0.7210469841957092]\n",
      "Epoch 2200, [D loss: 0.7443994283676147], [G loss: 0.9452117085456848]\n",
      "Epoch 2300, [D loss: 0.7743065357208252], [G loss: 0.6916235089302063]\n",
      "Epoch 2400, [D loss: 0.588702917098999], [G loss: 1.0995570421218872]\n",
      "Epoch 2500, [D loss: 0.7374933362007141], [G loss: 0.6431360840797424]\n",
      "Epoch 2600, [D loss: 0.6981170177459717], [G loss: 0.7757993340492249]\n",
      "Epoch 2700, [D loss: 0.6659213304519653], [G loss: 0.7044881582260132]\n",
      "Epoch 2800, [D loss: 0.6696951389312744], [G loss: 0.7497382760047913]\n",
      "Epoch 2900, [D loss: 0.7365707755088806], [G loss: 0.6744160652160645]\n",
      "Epoch 3000, [D loss: 0.7180644273757935], [G loss: 0.9001803398132324]\n",
      "Epoch 3100, [D loss: 0.5568086504936218], [G loss: 0.7617210149765015]\n",
      "Epoch 3200, [D loss: 0.6673337817192078], [G loss: 0.9005646109580994]\n",
      "Epoch 3300, [D loss: 0.5908448696136475], [G loss: 0.7884373664855957]\n",
      "Epoch 3400, [D loss: 0.7176947593688965], [G loss: 0.6726985573768616]\n",
      "Epoch 3500, [D loss: 0.6167925596237183], [G loss: 0.7886831760406494]\n",
      "Epoch 3600, [D loss: 0.7550793886184692], [G loss: 0.7913628816604614]\n",
      "Epoch 3700, [D loss: 0.5310481190681458], [G loss: 1.0999685525894165]\n",
      "Epoch 3800, [D loss: 0.561582088470459], [G loss: 1.132269263267517]\n",
      "Epoch 3900, [D loss: 0.7209219932556152], [G loss: 0.620774507522583]\n",
      "Epoch 4000, [D loss: 0.6620522737503052], [G loss: 0.8091919422149658]\n",
      "Epoch 4100, [D loss: 0.7467058897018433], [G loss: 0.5905636548995972]\n",
      "Epoch 4200, [D loss: 0.6776456236839294], [G loss: 0.7834081649780273]\n",
      "Epoch 4300, [D loss: 0.6643981337547302], [G loss: 0.7475945353507996]\n",
      "Epoch 4400, [D loss: 0.6769900321960449], [G loss: 0.6969387531280518]\n",
      "Epoch 4500, [D loss: 0.6652562618255615], [G loss: 0.8328988552093506]\n",
      "Epoch 4600, [D loss: 0.5972392559051514], [G loss: 0.8113340139389038]\n",
      "Epoch 4700, [D loss: 0.6387696266174316], [G loss: 0.6456912159919739]\n",
      "Epoch 4800, [D loss: 0.7664213180541992], [G loss: 0.6512011885643005]\n",
      "Epoch 4900, [D loss: 0.6581403017044067], [G loss: 0.8840538263320923]\n",
      "\u001b[1m3004/3004\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 15 columns):\n",
      " #   Column                    Non-Null Count   Dtype  \n",
      "---  ------                    --------------   -----  \n",
      " 0   Gender                    100000 non-null  float64\n",
      " 1   Age                       100000 non-null  float64\n",
      " 2   Category                  100000 non-null  float64\n",
      " 3   Item Purchased            100000 non-null  float64\n",
      " 4   Size                      100000 non-null  float64\n",
      " 5   Color                     100000 non-null  float64\n",
      " 6   Season                    100000 non-null  float64\n",
      " 7   Location                  100000 non-null  float64\n",
      " 8   Subscription Status       100000 non-null  float64\n",
      " 9   Payment Method            100000 non-null  float64\n",
      " 10  Shipping Type             100000 non-null  float64\n",
      " 11  Preferred Payment Method  100000 non-null  float64\n",
      " 12  Previous Purchases        100000 non-null  float64\n",
      " 13  Review Rating             100000 non-null  float64\n",
      " 14  Frequency of Purchases    100000 non-null  float64\n",
      "dtypes: float64(15)\n",
      "memory usage: 11.4 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Input, Dense, LeakyReLU\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Load data\n",
    "df = data_rf  \n",
    "\n",
    "# Normalize data to [0, 1]\n",
    "scaler = MinMaxScaler()\n",
    "df_scaled = scaler.fit_transform(df)\n",
    "\n",
    "# Function to build generator\n",
    "def build_generator(latent_dim, num_features):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_dim=latent_dim))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dense(256))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dense(512))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dense(num_features, activation='tanh'))\n",
    "    return model\n",
    "\n",
    "# Function to build discriminator\n",
    "def build_discriminator(num_features):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, input_dim=num_features))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dense(256))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dense(128))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "@tf.function\n",
    "def train_step(real_data, generator, discriminator, gan, batch_size, latent_dim):\n",
    "    noise = tf.random.normal([batch_size, latent_dim])\n",
    "    fake_data = generator(noise)\n",
    "\n",
    "    real_labels = tf.ones((batch_size, 1))\n",
    "    fake_labels = tf.zeros((batch_size, 1))\n",
    "\n",
    "    with tf.GradientTape() as disc_tape:\n",
    "        real_output = discriminator(real_data, training=True)\n",
    "        fake_output = discriminator(fake_data, training=True)\n",
    "        d_loss_real = tf.keras.losses.binary_crossentropy(real_labels, real_output)\n",
    "        d_loss_fake = tf.keras.losses.binary_crossentropy(fake_labels, fake_output)\n",
    "        d_loss = 0.5 * (d_loss_real + d_loss_fake)\n",
    "    \n",
    "    gradients_of_discriminator = disc_tape.gradient(d_loss, discriminator.trainable_variables)\n",
    "    discriminator.optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "\n",
    "    noise = tf.random.normal([batch_size, latent_dim])\n",
    "    misleading_labels = tf.ones((batch_size, 1))\n",
    "\n",
    "    with tf.GradientTape() as gen_tape:\n",
    "        fake_data = generator(noise, training=True)\n",
    "        fake_output = discriminator(fake_data, training=False)\n",
    "        g_loss = tf.keras.losses.binary_crossentropy(misleading_labels, fake_output)\n",
    "    \n",
    "    gradients_of_generator = gen_tape.gradient(g_loss, generator.trainable_variables)\n",
    "    generator.optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "\n",
    "    return d_loss, g_loss\n",
    "\n",
    "def train_gan(data, latent_dim, num_epochs=10000, batch_size=128, print_interval=100, learning_rate=0.0002, beta_1=0.5):\n",
    "    num_features = data.shape[1]\n",
    "\n",
    "    # Initialize discriminator\n",
    "    discriminator = build_discriminator(num_features)\n",
    "    discriminator.compile(optimizer=Adam(learning_rate=learning_rate, beta_1=beta_1))\n",
    "\n",
    "    # Initialize generator\n",
    "    generator = build_generator(latent_dim, num_features)\n",
    "    generator.compile(optimizer=Adam(learning_rate=learning_rate, beta_1=beta_1))\n",
    "\n",
    "    # Initialize GAN\n",
    "    gan = Sequential([generator, discriminator])\n",
    "    gan.compile(optimizer=Adam(learning_rate=learning_rate, beta_1=beta_1))\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        idx = np.random.randint(0, len(data), batch_size)\n",
    "        real_data = data[idx]\n",
    "\n",
    "        d_loss, g_loss = train_step(real_data, generator, discriminator, gan, batch_size, latent_dim)\n",
    "\n",
    "        # Print results\n",
    "        if epoch % print_interval == 0:\n",
    "            print(f\"Epoch {epoch}, [D loss: {d_loss.numpy().mean()}], [G loss: {g_loss.numpy().mean()}]\")\n",
    "\n",
    "    return generator\n",
    "\n",
    "# Train GAN with new parameters\n",
    "latent_dim = 100\n",
    "generator = train_gan(df_scaled, latent_dim, num_epochs=5000, batch_size=256, print_interval=100, learning_rate=0.0001,\n",
    "                      beta_1=0.9)\n",
    "\n",
    "# Function to generate synthetic data\n",
    "def generate_fake_data(generator, latent_dim, num_samples):\n",
    "    noise = np.random.normal(0, 1, (num_samples, latent_dim))\n",
    "    synthetic_data = generator.predict(noise)\n",
    "    # Convert from [-1, 1] to [0, 1]\n",
    "    synthetic_data = (synthetic_data + 1) / 2\n",
    "    return synthetic_data\n",
    "\n",
    "# Generate synthetic data\n",
    "num_samples = 100000 - len(df)\n",
    "synthetic_data = generate_fake_data(generator, latent_dim, num_samples)\n",
    "\n",
    "# Inverse transform to get original scale\n",
    "synthetic_data = scaler.inverse_transform(synthetic_data)\n",
    "\n",
    "# Chuyển đổi dữ liệu giả mạo mới sang DataFrame\n",
    "synthetic_df_new = pd.DataFrame(synthetic_data, columns=df.columns)\n",
    "\n",
    "# Kết hợp dữ liệu mới với dữ liệu cũ\n",
    "combined_df = pd.concat([df, synthetic_df_new], ignore_index=True)\n",
    "\n",
    "# Hiển thị thông tin của dữ liệu mới\n",
    "print(combined_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ca2de8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Frequency of Purchases      1.00\n",
       "Preferred Payment Method    0.53\n",
       "Color                       0.51\n",
       "Gender                      0.48\n",
       "Payment Method              0.40\n",
       "Size                        0.33\n",
       "Season                      0.31\n",
       "Category                    0.31\n",
       "Age                         0.22\n",
       "Shipping Type               0.15\n",
       "Item Purchased              0.13\n",
       "Previous Purchases          0.10\n",
       "Location                   -0.02\n",
       "Review Rating              -0.21\n",
       "Subscription Status        -0.34\n",
       "Name: Frequency of Purchases, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.corr()['Frequency of Purchases'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1ebf045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Category</th>\n",
       "      <th>Item Purchased</th>\n",
       "      <th>Size</th>\n",
       "      <th>Color</th>\n",
       "      <th>Season</th>\n",
       "      <th>Location</th>\n",
       "      <th>Subscription Status</th>\n",
       "      <th>Payment Method</th>\n",
       "      <th>Shipping Type</th>\n",
       "      <th>Preferred Payment Method</th>\n",
       "      <th>Previous Purchases</th>\n",
       "      <th>Review Rating</th>\n",
       "      <th>Frequency of Purchases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>2</td>\n",
       "      <td>54</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>39</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>2</td>\n",
       "      <td>62</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>37</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Gender  Age  Category  Item Purchased  Size  Color  Season  Location  \\\n",
       "99995       2   54         3              14     3     20       3        30   \n",
       "99996       2   62         4              20     3     22       3        29   \n",
       "99997       2   52         3              17     3     21       3        31   \n",
       "99998       2   60         3              16     3     19       3        31   \n",
       "99999       2   60         3              19     3     20       3        28   \n",
       "\n",
       "       Subscription Status  Payment Method  Shipping Type  \\\n",
       "99995                    2               5              5   \n",
       "99996                    2               6              4   \n",
       "99997                    2               5              4   \n",
       "99998                    1               5              4   \n",
       "99999                    1               5              5   \n",
       "\n",
       "       Preferred Payment Method  Previous Purchases  Review Rating  \\\n",
       "99995                         4                  39              3   \n",
       "99996                         4                  43              4   \n",
       "99997                         4                  37              4   \n",
       "99998                         4                  40              3   \n",
       "99999                         4                  40              3   \n",
       "\n",
       "       Frequency of Purchases  \n",
       "99995                       6  \n",
       "99996                       6  \n",
       "99997                       6  \n",
       "99998                       5  \n",
       "99999                       6  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df = combined_df.round().astype(int)\n",
    "combined_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc3047c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'datafake/100000.csv'\n",
    "combined_df.to_csv(file_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
